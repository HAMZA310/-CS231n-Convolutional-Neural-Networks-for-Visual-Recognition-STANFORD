{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_2_ first iteration_Q_learning_code_from_NP_to_PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAMZA310/-CS231n-Convolutional-Neural-Networks-for-Visual-Recognition-STANFORD/blob/master/week_2__first_iteration_Q_learning_code_from_NP_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzctCfyzxuAv"
      },
      "source": [
        "#### TO DO:\n",
        "`Make the minium possible changes to convert to PyTorch. No premature optimizations. No vectorizations. Let the loops stay. All optimizations in the next interations.`\n",
        "\n",
        "### Notes\n",
        "- Write unit tests to make sure each tensor equivalent is exactly equivalent to Numpy Operation.\n",
        "- Unit tests on checking shapes are also very important.\n",
        "- See if loops are avoidable. For example, bmm (batch mat mul is at your disposal).\n",
        "- Check if converting scalars to tensors provides a speedup? Checked. Not noticeable. But it's not a bad idea to put everything in a tensor.\n",
        "\n",
        "\n",
        "### From coder\n",
        "The important test case is the CartPole environment (you can search the colab document for that). If you want to have more low-level control, the relevant case is when the methods add_point, update_Q, estimate Q are called repeatedly in a loop for as long as is feasible. For the add_point method, you can set s, a, r, and s' however you like, as long as s and s' always have the same dimension, a is in {0, ..., self.A - 1}, and r is in [0, 1].\n",
        "\n",
        "\n",
        "We haven't yet written the theoretical resource this code is most precisely based on. However, what's being encoded here is using [Guassian processes](http://mlg.eng.cam.ac.uk/teaching/4f13/1920/gp%20and%20data.pdf) to estimate a [finite-horizon](https://arxiv.org/pdf/1909.03906.pdf) version of the Q-value of a state-action pair in a Markov Decision Process. Q_S[depth] contains estimates of the expectation of the average reward over the next `depth` timesteps after starting in state s and taking action a, for all (s, a) pairs we have observed so far. Then the method pictured above comes up with an estimate for an arbitrary state-action pair.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKuYykh_8F_b",
        "outputId": "c702cd78-e66c-4b8e-938f-0903bb871839"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "_device = 'cpu' # or 'cuda"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHxKBMFY9ZkZ"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.special import betaincinv, erfinv\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9AcHRT9a0YL"
      },
      "source": [
        "# No Numpy code in this cell\n",
        "\n",
        "import time\n",
        "class Check():\n",
        "    def __init__(self):\n",
        "        self.checkpoint_dict = dict()\n",
        "        self.last_check = None\n",
        "        self.last_time = None\n",
        "    def check(self, checkpoint_name):\n",
        "        now = time.time()\n",
        "        if self.last_check is not None:\n",
        "            interval_name = self.last_check + \" -> \" + checkpoint_name\n",
        "            if interval_name not in self.checkpoint_dict:\n",
        "                self.checkpoint_dict[interval_name] = []\n",
        "            self.checkpoint_dict[interval_name].append(now - self.last_time)\n",
        "        self.last_check = checkpoint_name\n",
        "        self.last_time = now\n",
        "    def print_total_times(self):\n",
        "        for interval in self.checkpoint_dict:\n",
        "            print(interval, \":\", sum(self.checkpoint_dict[interval]))\n",
        "    def reset(self):\n",
        "        self.__init__()\n",
        "check = Check()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IeX5atiSszW"
      },
      "source": [
        "# torch Tensors Version\n",
        "import matplotlib.tri as mtri\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def tensor_array(arr, shape_if_empty):\n",
        "    #############   FIX NEEDED ##########\n",
        "    ### TO DO: should return a Tensor not a list\n",
        "    #############   FIX NEEDED ##########\n",
        "\n",
        "\n",
        "    \"arr is of type list\"\n",
        "    if len(arr) == 0:\n",
        "        return [torch.tensor([]).reshape(shape_if_empty)]\n",
        "\n",
        "    # tensor = torch.tensor(arr)\n",
        "    # print(f'after conversion got {tensor}')\n",
        "    # return arr\n",
        "    return [elm.reshape(1,-1) for elm in arr] # This is reshaped to a higher dimension in np version\n",
        "\n",
        "def tensor_concat(pair):\n",
        "    \"pair is of type 'tuple'/'pair'\"\n",
        "    if len(pair[0]) == 0:\n",
        "        return torch.tensor([pair[1]])\n",
        "    else:\n",
        "        return torch.cat(pair)\n",
        "\n",
        "class Tn_QueueQGP(object):\n",
        "    def __init__(\n",
        "        self, n_actions, kernel, kernel_batch, \n",
        "        states, actions, rewards, next_states, \n",
        "        dones, done_value=0, optimistic=True, \n",
        "        bias_count=1, float_type=torch.float32, \n",
        "        advantage_learning=True\n",
        "        ):\n",
        "        \"Assume that if it's array like, then it's a tensor\"\n",
        "        \"Assume scalars are Python ints or floats for now\"\n",
        "\n",
        "        # TO DO: Convert all to tensors. using `torch.tensor(x)`\n",
        "        self.A = n_actions\n",
        "        self.k = kernel\n",
        "        self.k_batch = kernel_batch\n",
        "        self.done_value = done_value\n",
        "        self.float_type = float_type\n",
        "        self.advantage_learning = advantage_learning\n",
        "\n",
        "        # Vars below are array-like mostly.\n",
        "        self.raw_S = states.to(float_type) \n",
        "        self.raw_S_ = next_states.to(float_type)\n",
        "        self.raw_R = rewards.to(float_type) \n",
        "        self.actions = actions\n",
        "\n",
        "\n",
        "        self.S = [self.raw_S[actions == a] for a in range(self.A)]\n",
        "        self.R = [self.raw_R[actions == a] for a in range(self.A)]\n",
        "        self.S_ = [self.raw_S_[actions == a] for a in range(self.A)]\n",
        "        self.dones = [dones[actions == a] for a in range(self.A)]\n",
        "        self.ns = [self.S[a].shape[0] for a in range(self.A)]\n",
        "        print(self.ns)\n",
        "        self.dim = states.shape[1]\n",
        "\n",
        "        self.max_var = 1/4 # 1/4 is the maximum variance of a distribution over [0, 1] # check float length compatibility\n",
        "        self.optimistic = optimistic\n",
        "        if self.optimistic:\n",
        "            self.baseline = 1\n",
        "        else:\n",
        "            self.baseline = 0\n",
        "        self.bias_count = bias_count\n",
        "        self.data_noise = self.max_var * self.bias_count\n",
        "        self.K = []\n",
        "        \n",
        "        # These nested for loops should be replaced with tensor operations.\n",
        "        for a in range(self.A):\n",
        "            self.K.append(torch.eye(self.ns[a]) * self.data_noise)\n",
        "            for i in range(self.ns[a]):\n",
        "                for j in range(i + 1):\n",
        "                    if i == j:\n",
        "                        assert(k(self.S[a][i], self.S[a][j]) == self.max_var)\n",
        "                    self.K[a][i][j] += k(self.S[a][i], self.S[a][j])\n",
        "                    self.K[a][j][i] = self.K[a][i][j]\n",
        "        \n",
        "        self.K_inv = [torch.linalg.pinv(self.K[a]) for a in range(self.A)]\n",
        "        self.K_SS_ = [\n",
        "                      [tensor_array(\n",
        "                          [self.K_S(s_, a_) for s_ in self.S_[a]]\n",
        "                          , shape_if_empty=(0, self.ns[a_])\n",
        "                          )\n",
        "                      for a_ in range(self.A)]\n",
        "                      for a in range(self.A)\n",
        "                      ] # indexed as K_SS_[action that s_ followed][action following s_][s_][s]\n",
        "         \n",
        "        self.w_SS_ = [\n",
        "                      [torch.mm(self.K_SS_[a][a_][0], self.K_inv[a_])\n",
        "                       for a_ in range(self.A)] \n",
        "                      for a in range(self.A)\n",
        "                      ] # indexed as w_SS_[action that s_ followed][action of interest][s_][s]\n",
        "        self.var_S_ = [[torch.tensor([self.max_var - self.w_SS_[a][a_][s_] * self.K_SS_[a][a_][s_]\\\n",
        "                         if (self.w_SS_[a][a_][s_] * self.K_SS_[a][a_][s_]).numel() > 0\\\n",
        "                         else self.max_var - torch.zeros(1)\\\n",
        "                         for s_ in range(len(self.S_[a]))]) for a_ in range(self.A)]\n",
        "                       for a in range(self.A)]\n",
        "        \n",
        "        if self.advantage_learning:\n",
        "            self.K_S_S__all = torch.tensor([self.k_batch(s, self.raw_S_) for s in self.raw_S_]) + self.data_noise * torch.eye(len(self.raw_S_))\n",
        "\n",
        "            self.K_inv_S_S__all = torch.linalg.pinv(self.K_S_S__all)\n",
        "\n",
        "            self.K_SS_all = torch.tensor([self.k_scaled(s, self.raw_S) for s in self.raw_S]) + self.data_noise * torch.eye(len(self.raw_S))\n",
        "            self.K_inv_SS_all = torch.linalg.pinv(self.K_SS_all)\n",
        "\n",
        "        self.Q_S = None\n",
        "        self.Q_S_ = None\n",
        "        self.V_S = None\n",
        "        self.V_S__all = None\n",
        "\n",
        "    def K_S(self, s, a):\n",
        "        return self.k_batch(s, self.S[a])\n",
        "        \n",
        "    def k_scaled(self, s_1, s_2):\n",
        "        min_S = torch.min(self.raw_S, axis=0).values\n",
        "        range_S = torch.max(self.raw_S, axis=0).values - min_S\n",
        "        return self.k(range_S * (s_1 - min_S), range_S * (s_2 - min_S))\n",
        "\n",
        "    def w(self, s, a):\n",
        "        # TO DO: Replaced @ with *. Verify if matrix multiplication is required.\n",
        "        return self.K_inv[a] * self.K_S(s, a)\n",
        "\n",
        "\n",
        "    def add_data_point(self, s, a, r, s_, done):\n",
        "        s = s.to(self.float_type)\n",
        "        r = r.to(self.float_type)\n",
        "        s_ = s_.to(self.float_type)\n",
        "\n",
        "        check.check(\"a\")\n",
        "        K_Ss = self.K_S(s, a)\n",
        "        # assert(not np.any(np.isnan(K_Ss)))\n",
        "        # check_K_s_S_ = np.array([self.k_scaled(s_, s__) for s__ in self.raw_S_])\n",
        "        if self.advantage_learning:\n",
        "            K_s_S_ = self.k_batch(s_, self.raw_S_)\n",
        "            # assert(np.all(np.isclose(check_K_s_S_, K_s_S_)))\n",
        "            K_sS_all = self.k_batch(s, self.raw_S)\n",
        "\n",
        "        self.raw_S = torch.vstack((self.raw_S, s.reshape(1, -1)))\n",
        "        self.raw_S_ = torch.vstack((self.raw_S_, s_.reshape(1, -1)))\n",
        "        self.raw_R = torch.cat((self.raw_R, torch.tensor([r])))\n",
        "        self.actions = torch.cat((self.actions, torch.tensor([a])))\n",
        "        self.S[a] = torch.vstack((self.S[a], s.reshape(1, -1)))\n",
        "        self.S_[a] = torch.vstack((self.S_[a], s_.reshape(1, -1)))\n",
        "        self.R[a] = torch.cat((self.R[a], torch.tensor([r])))\n",
        "        self.dones[a] = torch.cat((self.dones[a], torch.tensor([done])))\n",
        "        self.ns[a] += 1\n",
        "        \n",
        "        # assert(self.k_scaled(s, s) == self.max_var)\n",
        "        if len(self.K[a]) == 0:\n",
        "            self.K[a] = torch.tensor([[self.max_var + self.data_noise]])\n",
        "        else:\n",
        "            self.K[a] = torch.hstack((tensor_concat((self.K[a], K_Ss.reshape(1, -1)))\\\n",
        "                                      , tensor_concat((K_Ss, torch.tensor([self.max_var + self.data_noise]))).reshape(-1, 1)))\n",
        "\n",
        "        check.check(\"b\")\n",
        "        K_inv_K_Ss = self.K_inv[a] @ K_Ss\n",
        "        K_inv_ss = torch.tensor([1 / (self.max_var + self.data_noise - K_inv_K_Ss @ K_Ss)])\n",
        "        self.K_inv[a] = self.K_inv[a] + K_inv_ss * torch.outer(K_inv_K_Ss, K_inv_K_Ss)\n",
        "        K_inv_K_Ss_K_inv_ss = - K_inv_ss * K_inv_K_Ss\n",
        "        self.K_inv[a] = torch.hstack((self.K_inv[a], K_inv_K_Ss_K_inv_ss.reshape(-1, 1)))\n",
        "        self.K_inv[a] = torch.vstack((self.K_inv[a], torch.cat((K_inv_K_Ss_K_inv_ss, K_inv_ss)).reshape(1, -1)))\n",
        "        check.check(\"c\")\n",
        "\n",
        "        if self.advantage_learning:\n",
        "            if len(self.K_S_S__all) == 0:\n",
        "                self.K_S_S__all = torch.tensor([[self.max_var + self.data_noise]])\n",
        "            else:\n",
        "                self.K_S_S__all = torch.hstack((tensor_concat((\n",
        "                    self.K_S_S__all, K_s_S_.reshape(1, -1)))\\\n",
        "                    , tensor_concat((K_s_S_, torch.tensor([self.max_var + self.data_noise]))).reshape(-1, 1)))\n",
        "            \n",
        "            K_inv_S_S__K_s_S_ = self.K_inv_S_S__all @ K_s_S_\n",
        "            K_inv_s_s_ = torch.tensor([1 / (self.max_var + self.data_noise - K_inv_S_S__K_s_S_ @ K_s_S_)])\n",
        "            self.K_inv_S_S__all = self.K_inv_S_S__all + K_inv_s_s_ * torch.outer(K_inv_S_S__K_s_S_, K_inv_S_S__K_s_S_)\n",
        "            K_inv_s_s__K_inv_S_S__K_s_S_ = - K_inv_s_s_ * K_inv_S_S__K_s_S_\n",
        "            self.K_inv_S_S__all = torch.hstack((self.K_inv_S_S__all, K_inv_s_s__K_inv_S_S__K_s_S_.reshape(-1, 1)))\n",
        "            self.K_inv_S_S__all = torch.vstack((self.K_inv_S_S__all, torch.cat((K_inv_s_s__K_inv_S_S__K_s_S_, K_inv_s_s_)).reshape(1, -1)))\n",
        "\n",
        "            if len(self.K_SS_all) == 0:\n",
        "                self.K_SS_all = torch.tensor([[self.max_var + self.data_noise]])\n",
        "            else:\n",
        "                self.K_SS_all = torch.hstack((tensor_concat(\n",
        "                    (self.K_SS_all, K_sS_all.reshape(1, -1)))\\\n",
        "                    , tensor_concat((K_sS_all, torch.tensor([self.max_var + self.data_noise]))).reshape(-1, 1)))\n",
        "            \n",
        "            K_inv_SS_K_sS = self.K_inv_SS_all @ K_sS_all\n",
        "            K_inv_ss_all = torch.tensor([1 / (self.max_var + self.data_noise - K_inv_SS_K_sS @ K_sS_all)])\n",
        "            self.K_inv_SS_all = self.K_inv_SS_all + K_inv_ss_all * torch.outer(K_inv_SS_K_sS, K_inv_SS_K_sS)\n",
        "            K_inv_ss_K_inv_SS_K_sS = - K_inv_ss_all * K_inv_SS_K_sS\n",
        "            self.K_inv_SS_all = torch.hstack((self.K_inv_SS_all, K_inv_ss_K_inv_SS_K_sS.reshape(-1, 1)))\n",
        "            self.K_inv_SS_all = torch.vstack((self.K_inv_SS_all, torch.cat((K_inv_ss_K_inv_SS_K_sS, K_inv_ss_all)).reshape(1, -1)))\n",
        "        for a__ in range(self.A):\n",
        "###################################################\n",
        "                    ######################################################################################################\n",
        "                    ######################################################################################################\n",
        "                    ###################################################\n",
        "\n",
        "            print(\n",
        "                'self.K_SS_[a__][a]', self.K_SS_[a__][a],\n",
        "                'K_inv_K_Ss', K_inv_K_Ss\n",
        "            )\n",
        "            self.w_SS_[a__][a] += K_inv_ss * torch.outer(\n",
        "                torch.mm(self.K_SS_[a__][a], K_inv_K_Ss)\\\n",
        "                ,K_inv_K_Ss\n",
        "                ) # because of change to self.K_inv[a][:-1, :-1]\n",
        "            if a__ != a:\n",
        "                ### TO DO: fix code duplication below\n",
        "                print('could be empty', self.K_SS_[a__][a])\n",
        "                is_kss_empty = ((self.K_SS_[a__][a])[0]).numel() == 0\n",
        "                \n",
        "                if not is_kss_empty:\n",
        "                    print('>>>> ')\n",
        "                    print(\n",
        "                        self.K_SS_[a__][a],\n",
        "                        self.k(s_, s)\n",
        "                    )\n",
        "                    \n",
        "                    self.K_SS_[a__][a] = torch.hstack((torch.tensor(self.K_SS_[a__][a]), torch.tensor([self.k(s_, s)\\\n",
        "                                                                                        for s_ in self.S_[a__]]).reshape(-1, 1)))\n",
        "                    print(\">> 1observe elements\", self.K_SS_)\n",
        "                else:\n",
        "                    self.K_SS_[a__][a] = torch.hstack((torch.tensor([]), torch.tensor([self.k(s_, s)\\\n",
        "                                                                                        for s_ in self.S_[a__]]).reshape(-1, 1)))\n",
        "                    print(\">> 2observe elements\", self.K_SS_)\n",
        "            else:\n",
        "                print('>>>> Else')\n",
        "                print(\n",
        "                    self.K_SS_[a__][a],\n",
        "                    self.k(s_, s)\n",
        "                )\n",
        "\n",
        "                is_kss_empty = ((self.K_SS_[a__][a])[0]).numel() == 0\n",
        "                if not is_kss_empty:\n",
        "                    self.K_SS_[a__][a] = torch.hstack((torch.tensor(self.K_SS_[a__][a]), torch.tensor([self.k(s_, s)\\\n",
        "                                                                                        for s_ in self.S_[a__][:-1]]).reshape(-1, 1)))\n",
        "                    print(\">> 3observe elements\", self.K_SS_)\n",
        "                else:\n",
        "                    self.K_SS_[a__][a] = torch.hstack((torch.tensor([]), torch.tensor([self.k(s_, s)\\\n",
        "                                                                                        for s_ in self.S_[a__][:-1]]).reshape(-1, 1)))\n",
        "                                                                                        \n",
        "                    print(\">> 4observe elements\", self.K_SS_)\n",
        "            self.w_SS_[a__][a] += torch.outer(self.K_SS_[a__][a][:, -1], K_inv_K_Ss_K_inv_ss) # because of change to last column of self.K_SS_[a__][a]\n",
        "            self.w_SS_[a__][a] = torch.hstack(\n",
        "                self.w_SS_[a__][a]\n",
        "                , torch.mm(self.K_SS_[a__][a], self.K_inv[a][:,-1]).reshape(-1, 1)\n",
        "                ) # because of extra column in self.K_inv[a]\n",
        "        print(\">> out observe elements\", self.K_SS_)\n",
        "        for a_ in range(self.A):\n",
        "            elm = self.K_SS_[a][a_]\n",
        "            # TO DO: You shoudn't need this hack i.e. elm[0].\n",
        "            print(\n",
        "                self.K_SS_[a][a_], '\\n', \n",
        "                elm, '<elm\\n',\n",
        "                self.w_SS_[a][a_]\n",
        "                )\n",
        "            if isinstance(elm, list):\n",
        "                self.K_SS_[a][a_] = torch.vstack(((elm[0]), (self.K_S(s_, a_))))\n",
        "                self.w_SS_[a][a_] = torch.vstack((self.w_SS_[a][a_], (elm[0][-1] * elf.K_inv[a_]).reshape(1, -1)))\n",
        "            else:\n",
        "                self.K_SS_[a][a_] = torch.vstack(((elm), (self.K_S(s_, a_))))\n",
        "                self.w_SS_[a][a_] = torch.vstack((self.w_SS_[a][a_], (elm[-1] * self.K_inv[a_]).reshape(1, -1)))\n",
        "        check.check(\"d\")\n",
        "\n",
        "    def update_Q(self, depth, verbose=False, visualization_dimension=[0, 1]):\n",
        "        check.check(\"f\")\n",
        "        if not self.advantage_learning:\n",
        "            self.Q_S = [[(self.R[a] - self.baseline) - self.data_noise * self.K_inv[a] @ (self.R[a] - self.baseline) + self.baseline\\\n",
        "                         for a in range(self.A)]] # indexed as Q_S[depth][action][state]\n",
        "        else:\n",
        "            # TO DO: replace elment-wise product with matrix mulitplication? Which is requried here? Matrix Multiplication is more likely.\n",
        "            IRE_S_raw = (torch.eye(self.raw_S.shape[0]) - self.data_noise * self.K_inv_SS_all) * (self.raw_R - self.baseline)\\\n",
        "                        + self.baseline  # I - self.data_noise * self.K_inv_SS_all = (self.K_SS_all - self.data_noise) * self.K_inv_SS_all\n",
        "            \n",
        "            x = self.K_inv_SS_all * (self.raw_R - self.baseline)\n",
        "            IRE_S__raw = torch.tensor([self.k_batch(s_, self.raw_S) * x + self.baseline for s_ in self.raw_S_]) # redoing lots of kernel evaluations\n",
        "            \n",
        "            \n",
        "            if verbose:\n",
        "                for IRE, data in zip([IRE_S_raw, IRE_S__raw], [self.raw_S, self.raw_S_]):\n",
        "                    triang = mtri.Triangulation(data[:, 0], data[:, 1])\n",
        "                    fig = plt.figure()\n",
        "                    ax = fig.add_subplot(1,1,1, projection='3d')\n",
        "                    ax.plot_trisurf(triang, IRE, cmap='jet')\n",
        "                    ax.scatter(data[:, 0],data[:, 1],IRE, marker='.', s=10, c=\"black\", alpha=0.5)\n",
        "                    ax.view_init(elev=60, azim=-45)\n",
        "                    ax.set_title(\"IRE\")\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "            IRE_S = [[] for a in range(self.A)]\n",
        "            IRE_S_ = [[] for a in range(self.A)]\n",
        "            for i in range(self.raw_S.shape[0]):\n",
        "                IRE_S[self.actions[i]].append(IRE_S_raw[i])\n",
        "                IRE_S_[self.actions[i]].append(IRE_S__raw[i])\n",
        "            IRE_S = [torch.tensor(arr) for arr in IRE_S]\n",
        "            IRE_S_ = [torch.tensor(arr) for arr in IRE_S_]\n",
        "\n",
        "           \n",
        "            self.Q_S = [[torch.tensor([self.w(s, a) * (self.R[a] - ire_s)\\\n",
        "                                       for s, ire_s in zip(self.S[a], IRE_S[a])]) + IRE_S[a]\\\n",
        "                         for a in range(self.A)]] # indexed as Q_S[depth][action][state]\n",
        "            \n",
        "        check.check(\"g\")\n",
        "        if self.advantage_learning:\n",
        "            print('in adv learning')\n",
        "            self.Q_S_ = [[[IRE_S_[a] + self.w_SS_[a][a_] * (self.Q_S[-1][a_] - IRE_S[a_])\\\n",
        "                           if (self.w_SS_[a][a_] * (self.Q_S[-1][a_] - IRE_S[a_])).numel() > 0\\\n",
        "                           else IRE_S_[a] + torch.zeros(IRE_S_[a].shape)\\\n",
        "                           for a_ in range(self.A)]\\\n",
        "                          for a in range(self.A)]] # indexed as Q_S_[depth][action][next action][next state]\n",
        "        else:\n",
        "            print('els adv learning')\n",
        "            self.Q_S_ = [[[self.baseline + self.w_SS_[a][a_] * (self.Q_S[-1][a_] - self.baseline) for a_ in range(self.A)] for a in range(self.A)]] # indexed as Q_S_[depth][action][next action][next state]\n",
        "       \n",
        "\n",
        "        if verbose and self.advantage_learning:\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(1,1,1, projection='3d')\n",
        "            for a in range(self.A):\n",
        "                triang = mtri.Triangulation(self.S[a][:, 0],self.S[a][:, 1])\n",
        "                ax.plot_trisurf(triang, self.Q_S[-1][a] - IRE_S[a], cmap='jet')\n",
        "                if a == 0:\n",
        "                    color = \"black\"\n",
        "                if a == 1:\n",
        "                    color = \"red\"\n",
        "                ax.scatter(self.S[a][:, 0],self.S[a][:, 1],self.Q_S[-1][a] - IRE_S[a], marker='.', s=10, c=color, alpha=0.5)\n",
        "                ax.set_title(\"Q_S[0] - IRE (on data)\")\n",
        "            ax.view_init(elev=10, azim=-45)\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(1,1,1, projection='3d')\n",
        "            for a_ in range(self.A):\n",
        "                X = torch.vstack([self.S_[a] for a in range(self.A)])\n",
        "                y = torch.cat([self.Q_S_[-1][a][a_] for a in range(self.A)]) - torch.cat([IRE_S_[a] for a in range(self.A)])\n",
        "                triang = mtri.Triangulation(X[:, 0],X[:, 1])\n",
        "                ax.plot_trisurf(triang, y, cmap='jet')\n",
        "                if a_ == 0:\n",
        "                    color = \"black\"\n",
        "                if a_ == 1:\n",
        "                    color = \"red\"\n",
        "                ax.scatter(X[:, 0],X[:, 1], y, marker='.', s=10, c=color, alpha=0.5)\n",
        "                ax.set_title(\"Q_S_[0] - IRE (on and off data)\")\n",
        "            ax.view_init(elev=10, azim=-45)\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(1,1,1, projection='3d')\n",
        "            for a_ in range(self.A):\n",
        "                X = torch.vstack([self.S_[a] for a in range(self.A)])\n",
        "                y = torch.cat([self.Q_S_[-1][a][a_] for a in range(self.A)])\n",
        "                triang = mtri.Triangulation(X[:, 0],X[:, 1])\n",
        "                ax.plot_trisurf(triang, y, cmap='jet')\n",
        "                if a_ == 0:\n",
        "                    color = \"black\"\n",
        "                if a_ == 1:\n",
        "                    color = \"red\"\n",
        "                ax.scatter(X[:, 0],X[:, 1], y, marker='.', s=10, c=color, alpha=0.5)\n",
        "                ax.set_title(\"Q_S_[0]\")\n",
        "            ax.view_init(elev=10, azim=-45)\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        if self.advantage_learning:\n",
        "            self.V_S_estimate = [IRE_S] # indexed V_S_estimate[depth][action following the state (just since that's how states are grouped)][state]\n",
        "            self.V_S__all = [IRE_S__raw] # indexed V_S__all[depth][state s_]\n",
        "        check.check(\"h\")\n",
        "        for itr, dep in enumerate(range(1, depth)):\n",
        "            V_S_ = [torch.tensor(self.Q_S_[-1][a]).max(axis=0).values\n",
        "                    if all(map(lambda elm: elm.numel() > 0, self.Q_S_[-1][a]))# If all are empty tensors, then max is also empty \n",
        "                    else torch.tensor([])\\\n",
        "                    for a in range(self.A)] # takes the maximum over next actions; indexed as V_S_[depth][action][next state]\n",
        "            \n",
        "            for a in range(self.A):\n",
        "                for s in range(self.ns[a]):\n",
        "                    if self.dones[a][s]:\n",
        "                        V_S_[a][s] = self.done_value\n",
        "            self.Q_S.append([(self.Q_S[0][a] + dep * V_S_[a])/(dep + 1) for a in range(self.A)])\n",
        "            check.check(\"i\")\n",
        "            \n",
        "            if self.advantage_learning:\n",
        "                self.V_S__all.append([])\n",
        "                i_a = [0 for _ in range(self.A)]\n",
        "                for i in range(self.raw_S_.shape[0]):\n",
        "                    a = self.actions[i]\n",
        "                    elm = V_S_[a]\n",
        "                    is_elm_empty = elm.numel() == 0\n",
        "                    if is_elm_empty:\n",
        "                        elm_to_append = torch.tensor([])\n",
        "                    else:\n",
        "                        elm_to_append = elm\n",
        "                    self.V_S__all[-1].append(elm_to_append)\n",
        "                    i_a[a] += 1\n",
        "                self.V_S__all[-1] = torch.tensor(self.V_S__all[-1])\n",
        "\n",
        "                self.V_S_estimate.append([[] for a in range(self.A)])\n",
        "                V_S__estimate = [[] for a in range(self.A)]\n",
        "                for i in range(self.raw_S.shape[0]):\n",
        "                    V_s = (self.K_inv_S_S__all * self.k_batch(self.raw_S[i], self.raw_S_)) * (self.V_S__all[-1] - self.baseline) + self.baseline\n",
        "                    V_s_ = (self.K_inv_S_S__all * self.k_batch(self.raw_S_[i], self.raw_S_)) * (self.V_S__all[-1] - self.baseline) + self.baseline\n",
        "                    self.V_S_estimate[-1][self.actions[i]].append(V_s)\n",
        "                    V_S__estimate[self.actions[i]].append(V_s_)\n",
        "                self.V_S_estimate[-1] = [torch.tensor(arr) for arr in self.V_S_estimate[-1]]\n",
        "                V_S__estimate = [torch.tensor(arr) for arr in V_S__estimate]\n",
        "                if verbose and dep == 1:\n",
        "                    fig = plt.figure()\n",
        "                    ax = fig.add_subplot(1,1,1, projection='3d')\n",
        "                    for a in range(self.A):\n",
        "                        triang = mtri.Triangulation(self.S[a][:, 0],self.S[a][:, 1])\n",
        "                        ax.plot_trisurf(triang, self.Q_S[-1][a] - self.V_S_estimate[-1][a], cmap='jet')\n",
        "                        if a == 0:\n",
        "                            color = \"black\"\n",
        "                        if a == 1:\n",
        "                            color = \"red\"\n",
        "                        ax.scatter(self.S[a][:, 0],self.S[a][:, 1],self.Q_S[-1][a] - self.V_S_estimate[-1][a], marker='.', s=10, c=color, alpha=0.5)\n",
        "                        ax.set_title(\"Q_S[1] - V_S_estimate[1] (on data)\")\n",
        "                    ax.view_init(elev=10, azim=-45)\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "            \n",
        "            if dep < depth - 1:\n",
        "                if self.advantage_learning:\n",
        "                    self.Q_S_.append([[V_S__estimate[a] + self.w_SS_[a][a_] * (self.Q_S[-1][a_] - self.V_S_estimate[-1][a_])\\\n",
        "                                       if (self.w_SS_[a][a_] * (self.Q_S[-1][a_] - self.V_S_estimate[-1][a_])).numel() > 0 # What should [] * 5 be? or [] + 5? Current fix ignores cases when other tesnors are []\n",
        "                                       else V_S__estimate[a]\n",
        "                                       for a_ in range(self.A)]\\\n",
        "                                      for a in range(self.A)])\n",
        "                else:\n",
        "                    self.Q_S_.append([[self.baseline + self.w_SS_[a][a_] * (self.Q_S[-1][a_] - self.baseline)\\\n",
        "                                       for a_ in range(self.A)]\\\n",
        "                                      for a in range(self.A)])   \n",
        "            check.check(\"j\")         \n",
        "\n",
        "    def estimate_Q(self, s, a, depth=-1):\n",
        "        s = s.to(self.float_type)\n",
        "        w = self.w(s, a)\n",
        "        Q_S = self.Q_S[depth][a]\n",
        "        if self.advantage_learning:\n",
        "            # Replaced @ with *. Verify if torch.mm is required.\n",
        "            V_s_estimate = (self.K_inv_S_S__all * self.k_batch(s, self.raw_S_)) * (self.V_S__all[depth] - self.baseline) + self.baseline\n",
        "            return V_s_estimate + w * (Q_S - self.V_S_estimate[depth][a]) if w.numel() > 0 else V_s_estimate\n",
        "        else:\n",
        "            return self.baseline + w * (Q_S - self.baseline) if w.numel() > 0 else self.baseline\n",
        "\n",
        "def k(s_1, s_2):\n",
        "    max_var = 1/4\n",
        "    return max_var * (1 - torch.mean(torch.abs(s_1 - s_2)))\n",
        "    # return max_var * 2 ** (- 2 * torch.mean(torch.abs(s_1 - s_2))) # k(s, s) must = max_var\n",
        "\n",
        "def k_batch(s_1, s_2s):\n",
        "    max_var = 1/4\n",
        "    return max_var * (1 - torch.mean(torch.abs(s_1.reshape(1, -1) - s_2s), axis=1))\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJ6KEmzaVTx"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nTBP-HjdyT"
      },
      "source": [
        "# Tensors Version\n",
        "class Tn_OptimisticAgent(object):\n",
        "    def __init__(self, n_actions, state_space_kernel=k, \n",
        "                 state_space_batch_kernel=k_batch, optimism=3, \n",
        "                 horizon=40, done_value=0):\n",
        "        self.A = n_actions\n",
        "        self.k = state_space_kernel\n",
        "        self.k_batch = state_space_batch_kernel\n",
        "        self.optimism = optimism\n",
        "        self.horizon = horizon\n",
        "        self.done_value = done_value\n",
        "        self.Q_estimator = None\n",
        "        self.t = 0\n",
        "    \n",
        "    def observe(self, state, action, reward, next_state, done):\n",
        "        if self.Q_estimator is None:\n",
        "            self.Q_estimator = Tn_QueueQGP(\n",
        "                self.A, self.k, self.k_batch, state.reshape(1, -1)\n",
        "                , torch.tensor([action]), torch.tensor([reward]), next_state.reshape(1, -1)\n",
        "                , torch.tensor([done]), done_value=self.done_value, optimistic=True, bias_count=self.optimism\n",
        "                )\n",
        "        else:\n",
        "            self.Q_estimator.add_data_point(state, torch.tensor(action), torch.tensor(reward), next_state, done)\n",
        "        self.Q_estimator.update_Q(self.horizon, verbose=self.t%20==19)\n",
        "\n",
        "    \n",
        "    def act(self, state):\n",
        "        self.t += 1\n",
        "        if self.Q_estimator is None:\n",
        "            return 0\n",
        "        t = torch.tensor(([self.Q_estimator.estimate_Q(state, a)\\\n",
        "                                          for a in range(self.A)\n",
        "                                          ]))\n",
        "        return torch.argmax(t)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "Ady_gbE9XBK2",
        "outputId": "db101dc2-7728-42bd-cb9d-e2b97b256cd9"
      },
      "source": [
        "estimator = Tn_QueueQGP(2, k, k_batch, torch.tensor([[0, 0]]), \n",
        "                        torch.tensor([0]), torch.tensor([0.5]), \n",
        "                        torch.tensor([[0.1, 0.1]]), torch.tensor([False]), \n",
        "                        done_value=0, optimistic=False, bias_count=1, \n",
        "                        advantage_learning=False)\n",
        "estimator.update_Q(4)\n",
        "for a in [0, 1]:\n",
        "    print(estimator.estimate_Q(torch.tensor([0.1, 0.1]), a))\n",
        "for i in range(1, 10):\n",
        "    estimator.add_data_point(i*torch.tensor([0.1, 0.1]), torch.tensor(i//2 % 2), \n",
        "                             torch.tensor(0.5), (i+1)*torch.tensor([0.1, 0.1]), False)\n",
        "    estimator.update_Q(4)\n",
        "    for a in [0, 1]: \n",
        "        print(estimator.estimate_Q((i+1)*torch.tensor([0.1, 0.1]), a))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0]\n",
            "els adv learning\n",
            "tensor([], size=(1, 0))\n",
            "0\n",
            "self.K_SS_[a__][a] [tensor([[0.2250]])] K_inv_K_Ss tensor([0.4500])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a607b5f169c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     estimator.add_data_point(i*torch.tensor([0.1, 0.1]), torch.tensor(i//2 % 2), \n\u001b[0;32m---> 11\u001b[0;31m                              torch.tensor(0.5), (i+1)*torch.tensor([0.1, 0.1]), False)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-662402c22a4e>\u001b[0m in \u001b[0;36madd_data_point\u001b[0;34m(self, s, a, r, s_, done)\u001b[0m\n\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m             self.w_SS_[a__][a] += K_inv_ss * torch.outer(\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK_SS_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_inv_K_Ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;34m,\u001b[0m\u001b[0mK_inv_K_Ss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 ) # because of change to self.K_inv[a][:-1, :-1]\n",
            "\u001b[0;31mTypeError\u001b[0m: mm(): argument 'input' (position 1) must be Tensor, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnGdC4v4YXfq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vDaR1sCYXaC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjA_iUskYXUG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGxm9ml6XDp6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V5GfTc00eKV"
      },
      "source": [
        "agent = Tn_OptimisticAgent(2, horizon=5)\n",
        "agent.observe(state=torch.tensor([0, 0]), \n",
        "              action=torch.tensor([0]), \n",
        "              reward=torch.tensor([0.1]), \n",
        "              next_state=torch.tensor([1, 0]), \n",
        "              done=False)\n",
        "\n",
        "a = agent.act(torch.tensor([1, 0]))\n",
        "print(a)\n",
        "\n",
        "print(([agent.Q_estimator.estimate_Q(torch.tensor([1, 0]), a, depth=-1) for a in range(2)]))\n",
        "agent.observe(\n",
        "    state=torch.tensor([1, 0]), \n",
        "    action=a,\n",
        "    reward=0.1, \n",
        "    next_state=torch.tensor([0, 0]),\n",
        "    done=False)\n",
        "a = agent.act(torch.tensor([0, 0]))\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTGw99jgBcs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-T6el21nrDL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}