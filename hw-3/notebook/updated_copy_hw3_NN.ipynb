{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of hw3_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAMZA310/-CS231n-Convolutional-Neural-Networks-for-Visual-Recognition-STANFORD/blob/master/hw-3/notebook/updated_copy_hw3_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ndLRl8Nn18i",
        "colab_type": "text"
      },
      "source": [
        "## Question 1\n",
        "#### d) \n",
        "Write a Python function to compute the gradients of this function given input\n",
        "$w_i$ and $x_i$ efficiently with backpropagation. (Write it from scratch.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6BQO0gjn0CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient_of_max_fn(params):\n",
        "    \"\"\"\n",
        "    Computes gradient of the function: max(w0, w1x1, w2x2, 0)\n",
        "    \n",
        "    \n",
        "    args: params -> tuple of len 5 => (w0, w1, x1, w2, x2)\n",
        "    \n",
        "    returns -> tuple of len 5 => (dw0, dw1, dx1, dw2, dx2) => gradient => \n",
        "                            parital derivatives w.r.t to f of w0, w1, x1, w2, x2\n",
        "                            respectively.\n",
        "    \"\"\"\n",
        "    \n",
        "    # unpack params \n",
        "    w0, w1, x1, w2, x2 = params\n",
        "    \n",
        "    # define a var z\n",
        "    z = w0 + w1*x1 + w2*x2\n",
        "    \n",
        "    # Initialize partial derivatives of each parameter w.r.t. fn to 0.\n",
        "    dw0, dw1, dx1, dw2, dx2 = (0,0,0,0,0)\n",
        "    \n",
        "    # if z is less or equal to 0, we're done. Gradient is a vector of 0s.\n",
        "    if z <= 0:\n",
        "        gradient = (dw0, dw1, dx1, dw2, dx2)\n",
        "        \n",
        "    # if z is greater than 0, then compute partial derivatives \n",
        "    else:\n",
        "        # partial derivative of f w.r.t. w0\n",
        "        dw0 = 1\n",
        "        # partial derivative of f w.r.t. w1\n",
        "        dw1 = x1\n",
        "        # partial derivative of f w.r.t. x1\n",
        "        dx1 = w1\n",
        "        # partial derivative of f w.r.t. w2\n",
        "        dw2 = x2\n",
        "        # partial derivative of f w.r.t. x2\n",
        "        dx2 = w2\n",
        "        gradient = (dw0, dw1, dx1, dw2, dx2)\n",
        "    \n",
        "    return gradient"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF706X1Zn_rK",
        "colab_type": "text"
      },
      "source": [
        "#### Test this function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oan60ikDn5qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7da6c615-80ec-46e7-d51d-476deb01aab8"
      },
      "source": [
        "_params = (5, -4, 2, -3, -2) # test on paramters given in part a of Q-1\n",
        "\n",
        "compute_gradient_of_max_fn(_params)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, -4, -2, -3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM71-HP5n7Fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "089bbf41-8065-4759-a80a-39cdf72b3918"
      },
      "source": [
        "_params = (10, -2, 4, -3, 2) # test on paramters given in part a of Q-1\n",
        "\n",
        "compute_gradient_of_max_fn(_params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 0, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYZiJebMn9zF",
        "colab_type": "text"
      },
      "source": [
        "Both gradients match to my response to `part a` and `part b` of `Q-1` respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDBQTwhBoC3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flh_A9E3oCpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EQu5iRuoCb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTbwIjxWoDSO",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDuNgEItLxnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn import datasets\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtSm4BekLnNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedforwardNeuralNetworkSGD:\n",
        "    \n",
        "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
        "    def __init__(self, layers, alpha = 0.1, batchSize = 32):\n",
        "        # list of weight matrices between layers\n",
        "        self.W = []\n",
        "        \n",
        "        # network architecture will be a vector of numbers of nodes for each layer\n",
        "        self.layers = layers\n",
        "        \n",
        "        # learning rate\n",
        "        self.alpha = alpha\n",
        "        \n",
        "        # batch size\n",
        "        self.batchSize = batchSize\n",
        "        \n",
        "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
        "        \n",
        "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
        "        for i in np.arange(0, len(layers) - 2):\n",
        "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
        "            \n",
        "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
        "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
        "        \n",
        "    # define the sigmoid activation\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0 / (1 + np.exp(-x))\n",
        "    \n",
        "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
        "    def sigmoidDerivative(self, z):\n",
        "        return z * (1 - z)\n",
        "    \n",
        "    def getNextBatch(self, X, y, batchSize):\n",
        "        for i in np.arange(0, X.shape[0], batchSize):\n",
        "            yield (X[i:i + batchSize], y[i:i + batchSize])\n",
        "    \n",
        "    # fit the model\n",
        "    def fit(self, X, y, testX, testY, epochs = 10000, update = 1000):\n",
        "        # add a column of ones to the end of X\n",
        "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
        "\n",
        "        # history keeps track of all loss/accuracy vs epoch number on Test data\n",
        "        loss_history = []\n",
        "        accuracy_history = []\n",
        "\n",
        "        for epoch in np.arange(0,epochs):\n",
        "            \n",
        "            # randomize the examples\n",
        "            p = np.arange(0,X.shape[0])\n",
        "            np.random.shuffle(p)\n",
        "            X = X[p]\n",
        "            y = y[p]\n",
        "\n",
        "            # feed forward, backprop, and weight update\n",
        "            for (x, target) in self.getNextBatch(X, y, self.batchSize):\n",
        "                # make a list of output activations from the first layer\n",
        "                # (just the original x values)\n",
        "                A = [np.atleast_2d(x)]\n",
        "                \n",
        "                # feed forward\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    \n",
        "                    # feed through one layer and apply sigmoid activation\n",
        "                    net = A[layer].dot(self.W[layer])\n",
        "                    out = self.sigmoid(net)\n",
        "                    \n",
        "                    # add our network output to the list of activations\n",
        "                    A.append(out)\n",
        "                    \n",
        "                # backpropagation (coming soon!)\n",
        "                error = A[-1] - target\n",
        "                \n",
        "                D = [error * self.sigmoidDerivative(A[-1])]\n",
        "                \n",
        "                # loop backwards over the layers to build up deltas\n",
        "                for layer in np.arange(len(A) - 2, 0, -1):\n",
        "                    delta = D[-1].dot(self.W[layer].T)\n",
        "                    delta = delta * self.sigmoidDerivative(A[layer])\n",
        "                    D.append(delta)\n",
        "                    \n",
        "                # reverse the deltas since we looped in reverse\n",
        "                D = D[::-1]\n",
        "                \n",
        "                # weight update\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    self.W[layer] -= self.alpha * A[layer].T.dot(D[layer])\n",
        "            \n",
        "            if (epoch + 1) % update == 0:\n",
        "                loss = self.computeLoss(X,y)\n",
        "                print(\"[INFO] epoch = {}, loss = {:.6f}\".format(epoch + 1, loss))\n",
        "\n",
        "\n",
        "################ Show test accuracy and record test accuracy and loss for plotting later ################\n",
        "            loss_Test = self.computeLoss(testX, testY, addOnes=True)\n",
        "            loss_history.append(loss_Test)\n",
        "\n",
        "            accuracy_testX = self.get_testing_accuracy(testX, testY, epoch)\n",
        "            accuracy_history.append(accuracy_testX)\n",
        "\n",
        "        return loss_history, accuracy_history\n",
        "################ Show test accuracy and record test accuracy and loss for plotting later ################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################ Member function to Display Test Accuracy for each epoch ################\n",
        "    def get_testing_accuracy(self, testX, testY, epoch):\n",
        "        predictedY = self.predict(testX)\n",
        "        predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "        testY = testY.argmax(axis=1)\n",
        "\n",
        "        accuracy_on_testX = accuracy_score(testY, predictedY)\n",
        "        report = classification_report(testY, predictedY)\n",
        "        print(\"[INFO] epoch = {}, accuracy = {}, classification report :\\n {}\".format(epoch + 1, \n",
        "                                                                    accuracy_on_testX, report))\n",
        "        return accuracy_on_testX\n",
        "################ Member function to Display Test Accuracy for each epoch ################\n",
        "\n",
        "\n",
        "    def predict(self, X, addOnes = True):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        p = np.atleast_2d(X)\n",
        "        \n",
        "        # add a column of 1s for bias\n",
        "        if addOnes:\n",
        "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
        "        \n",
        "        # feed forward!\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            # print('shapes, p and ws', p.shape, self.W[layer].shape)\n",
        "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
        "            \n",
        "        return p\n",
        "    \n",
        "    def computeLoss(self, X, y, addOnes=False):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        y = np.atleast_2d(y)\n",
        "        \n",
        "        # feed the datapoints through the network to get predicted outputs\n",
        "        predictions = self.predict(X, addOnes = addOnes)\n",
        "        loss = np.sum((predictions - y)**2) / 2.0\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnzpmubcLocl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60793922-4654-42e7-81ce-cc6bddfac47d"
      },
      "source": [
        "### CLASSIFY MNIST PICTURES\n",
        "\n",
        "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
        "data = mnist.load_data()\n",
        "\n",
        "# The datapoints are in mnistData[0][0]\n",
        "X = data[0][0][:10000].reshape([10000,28*28])\n",
        "X = X/255.0\n",
        "\n",
        "# The labels are in mnistData[0][1]\n",
        "Y = data[0][1][:10000]\n",
        "\n",
        "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size = 0.25)\n",
        "\n",
        "print(trainX.shape)\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# fit the model to the training data\n",
        "model = FeedforwardNeuralNetworkSGD([784, 256, 128, 64, 10], 0.5, 32)\n",
        "#model = FeedforwardNeuralNetworkSGD([64, 16, 16, 10], 0.5, 32)\n",
        "loss_history, accuracy_history = model.fit(trainX, trainY, testX, testY, 1000, 100)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 724, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 725, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 726, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 727, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 728, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 729, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 730, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 731, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 732, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 733, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 734, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 735, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 736, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       1.00      0.00      0.01       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.14      0.12      0.04      2500\n",
            "weighted avg       0.15      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 737, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 738, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 739, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 740, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 741, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 742, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 743, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 744, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 745, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 746, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 747, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 748, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 749, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 750, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 751, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.20      0.03      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.04      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 752, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 753, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 754, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 755, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 756, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 757, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 758, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 759, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 760, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 761, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 762, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 763, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 764, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 765, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 766, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 767, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 768, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 769, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 770, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 771, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 772, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 773, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 774, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 775, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 776, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 777, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 778, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 779, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 780, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 781, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 782, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 783, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 784, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 785, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 786, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 787, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 788, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 789, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 790, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 791, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 792, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.86      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.04      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 793, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 794, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 795, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 796, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 797, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 798, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 799, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 800, loss = 3749.999944\n",
            "[INFO] epoch = 800, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 801, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 802, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 803, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 804, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 805, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 806, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 807, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 808, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 809, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 810, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 811, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 812, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 813, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 814, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 815, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 816, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 817, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 818, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.22      0.04      0.06       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 819, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 820, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 821, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 822, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 823, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 824, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 825, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 826, accuracy = 0.1152, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.12      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.12      0.04      2500\n",
            "\n",
            "[INFO] epoch = 827, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 828, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 829, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 830, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 831, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 832, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 833, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 834, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 835, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 836, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 837, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 838, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 839, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 840, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 841, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 842, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 843, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 844, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.24      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 845, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 846, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 847, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 848, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 849, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 850, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 851, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 852, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 853, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 854, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 855, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 856, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 857, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 858, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 859, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 860, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 861, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 862, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 863, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 864, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 865, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 866, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 867, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 868, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 869, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 870, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 871, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 872, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 873, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 874, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 875, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 876, accuracy = 0.1148, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.33      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.05      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 877, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 878, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 879, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 880, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 881, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.25      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 882, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 883, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 884, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 885, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 886, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 887, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 888, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 889, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 890, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 891, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 892, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 893, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 894, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 895, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 896, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 897, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 898, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 899, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 900, loss = 3749.999942\n",
            "[INFO] epoch = 900, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 901, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 902, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 903, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 904, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 905, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 906, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 907, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 908, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 909, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 910, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 911, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 912, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 913, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 914, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 915, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 916, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 917, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 918, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 919, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 920, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 921, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 922, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 923, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 924, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 925, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 926, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 927, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 928, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 929, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 930, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 931, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.26      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 932, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.27      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 933, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.27      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 934, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.27      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 935, accuracy = 0.114, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 936, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 937, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 938, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 939, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 940, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 941, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 942, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 943, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 944, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 945, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 946, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 947, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 948, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 949, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 950, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 951, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 952, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 953, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 954, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 955, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 956, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 957, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 958, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 959, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 960, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 961, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 962, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 963, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 964, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 965, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 966, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 967, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 968, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 969, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 970, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 971, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 972, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 973, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 974, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 975, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 976, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 977, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 978, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 979, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 980, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 981, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 982, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 983, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 984, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 985, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 986, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 987, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 988, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 989, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 990, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 991, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 992, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 993, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 994, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 995, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 996, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.28      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 997, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.29      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 998, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.29      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 999, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.29      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n",
            "[INFO] epoch = 1000, loss = 3749.999939\n",
            "[INFO] epoch = 1000, accuracy = 0.1144, classification report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.29      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayJKQjlMJqPq",
        "colab_type": "text"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfIkhw5ub7KY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a9fb438-2b20-477c-d8ab-73be78306ad2"
      },
      "source": [
        "# Plot Loss vs epoch\n",
        "plt.plot(loss_history)\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot test accuracy vs epoch\n",
        "plt.plot(accuracy_history)\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# print the classification performance\n",
        "print(\"Training set accuracy\")\n",
        "predictedY = model.predict(trainX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "trainY = trainY.argmax(axis=1)\n",
        "print(classification_report(trainY, predictedY))\n",
        "\n",
        "print(\"Test set accuracy\")\n",
        "predictedY = model.predict(testX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "testY = testY.argmax(axis=1)\n",
        "print(classification_report(testY, predictedY))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       745\n",
            "           1       1.00      0.00      0.01       859\n",
            "           2       0.00      0.00      0.00       731\n",
            "           3       0.00      0.00      0.00       782\n",
            "           4       0.11      0.90      0.20       742\n",
            "           5       0.11      0.26      0.16       648\n",
            "           6       0.20      0.04      0.07       751\n",
            "           7       0.00      0.00      0.00       788\n",
            "           8       0.00      0.00      0.00       697\n",
            "           9       0.00      0.00      0.00       757\n",
            "\n",
            "    accuracy                           0.12      7500\n",
            "   macro avg       0.14      0.12      0.04      7500\n",
            "weighted avg       0.16      0.12      0.04      7500\n",
            "\n",
            "Test set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       256\n",
            "           1       0.00      0.00      0.00       268\n",
            "           2       0.00      0.00      0.00       260\n",
            "           3       0.00      0.00      0.00       250\n",
            "           4       0.11      0.87      0.19       238\n",
            "           5       0.13      0.32      0.19       215\n",
            "           6       0.29      0.04      0.07       263\n",
            "           7       0.00      0.00      0.00       282\n",
            "           8       0.00      0.00      0.00       247\n",
            "           9       0.00      0.00      0.00       221\n",
            "\n",
            "    accuracy                           0.11      2500\n",
            "   macro avg       0.05      0.12      0.04      2500\n",
            "weighted avg       0.05      0.11      0.04      2500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8O_ypWXU8R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gusq4_s5U9Qw",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_qfr0B1U8KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedforwardNeuralNetworkSGDWithRegularization:\n",
        "    \n",
        "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
        "    def __init__(self, layers, alpha = 0.1, batchSize = 32):\n",
        "        # list of weight matrices between layers\n",
        "        self.W = []\n",
        "        \n",
        "        # network architecture will be a vector of numbers of nodes for each layer\n",
        "        self.layers = layers\n",
        "        \n",
        "        # learning rate\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Regularization parameter\n",
        "        self.lambda_ = 0.1\n",
        "        \n",
        "        # batch size\n",
        "        self.batchSize = batchSize\n",
        "        \n",
        "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
        "        \n",
        "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
        "        for i in np.arange(0, len(layers) - 2):\n",
        "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
        "            \n",
        "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
        "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
        "        \n",
        "    # define the sigmoid activation\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0 / (1 + np.exp(-x))\n",
        "    \n",
        "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
        "    def sigmoidDerivative(self, z):\n",
        "        return z * (1 - z)\n",
        "    \n",
        "    def getNextBatch(self, X, y, batchSize):\n",
        "        for i in np.arange(0, X.shape[0], batchSize):\n",
        "            yield (X[i:i + batchSize], y[i:i + batchSize])\n",
        "    \n",
        "    # fit the model\n",
        "    def fit(self, X, y, testX, testY, epochs = 10000, update = 1000):\n",
        "        # add a column of ones to the end of X\n",
        "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
        "\n",
        "        # history keeps track of all loss/accuracy vs epoch number on Test data\n",
        "        loss_history = []\n",
        "        accuracy_history = []\n",
        "\n",
        "        for epoch in np.arange(0,epochs):\n",
        "            \n",
        "            # randomize the examples\n",
        "            p = np.arange(0,X.shape[0])\n",
        "            np.random.shuffle(p)\n",
        "            X = X[p]\n",
        "            y = y[p]\n",
        "\n",
        "            # feed forward, backprop, and weight update\n",
        "            for (x, target) in self.getNextBatch(X, y, self.batchSize):\n",
        "                # make a list of output activations from the first layer\n",
        "                # (just the original x values)\n",
        "                A = [np.atleast_2d(x)]\n",
        "                \n",
        "                # feed forward\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    \n",
        "                    # feed through one layer and apply sigmoid activation\n",
        "                    net = A[layer].dot(self.W[layer])\n",
        "                    out = self.sigmoid(net)\n",
        "                    \n",
        "                    # add our network output to the list of activations\n",
        "                    A.append(out)\n",
        "                    \n",
        "                # backpropagation \n",
        "                error = A[-1] - target\n",
        "                \n",
        "                D = [error * self.sigmoidDerivative(A[-1])]\n",
        "                # loop backwards over the layers to build up deltas\n",
        "                for layer in np.arange(len(A)-2, 0, -1):\n",
        "                    delta = D[-1].dot(self.W[layer].T)\n",
        "                    delta = delta * self.sigmoidDerivative(A[layer])\n",
        "                    D.append(delta)\n",
        "\n",
        "                # reverse the deltas since we looped in reverse\n",
        "                D = D[::-1]\n",
        "\n",
        "\n",
        "################ Weight update with regularization incorporated ################\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    \"Add the extra regularization term\"\n",
        "                    self.W[layer] -= self.alpha  *  (A[layer].T.dot(D[layer])+self.lambda_*self.W[layer])\n",
        "################ Weight update with regularization incorporated ################\n",
        "\n",
        "\n",
        "\n",
        "################ Loss update to incorporate L-2 Regularization ################\n",
        "            Ws_sq_sum = 0\n",
        "            for i in range(len(self.W)):\n",
        "                Ws_sq_sum += np.sum(self.W[i]**2)\n",
        "\n",
        "            if (epoch + 1) % update == 0:\n",
        "                loss = self.computeLoss(X,y) + Ws_sq_sum\n",
        "                print(\"[INFO] epoch = {}, loss = {:.6f}\".format(epoch + 1, loss))\n",
        "################ Loss update to incorporate L-2 Regularization ################\n",
        "\n",
        "            loss_Test = self.computeLoss(testX, testY, addOnes=True) + Ws_sq_sum\n",
        "            loss_history.append(loss_Test)\n",
        "\n",
        "            accuracy_testX = self.get_testing_accuracy(testX, testY, epoch)\n",
        "            accuracy_history.append(accuracy_testX)\n",
        "\n",
        "        return loss_history, accuracy_history\n",
        "\n",
        "\n",
        "    def get_testing_accuracy(self, testX, testY, epoch):\n",
        "        predictedY = self.predict(testX)\n",
        "        predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "        testY = testY.argmax(axis=1)\n",
        "\n",
        "        accuracy_on_testX = accuracy_score(testY, predictedY)\n",
        "        \"Uncomment below to display classification report for Test data\"\n",
        "        # report = classification_report(testY, predictedY)\n",
        "        # print(\"[INFO] epoch = {}, accuracy = {}, classification report :\\n {}\".format(epoch + 1, \n",
        "        #                                                             accuracy_on_testX, report))\n",
        "        return accuracy_on_testX\n",
        "\n",
        "    def predict(self, X, addOnes = True):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        p = np.atleast_2d(X)\n",
        "        \n",
        "        # add a column of 1s for bias\n",
        "        if addOnes:\n",
        "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
        "        \n",
        "        # feed forward!\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
        "            \n",
        "        return p\n",
        "    \n",
        "    def computeLoss(self, X, y, addOnes=False):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        y = np.atleast_2d(y)\n",
        "        \n",
        "        # feed the datapoints through the network to get predicted outputs\n",
        "        predictions = self.predict(X, addOnes = addOnes)\n",
        "        loss = np.sum((predictions - y)**2) / 2.0\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5_Q6BGfLqSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "03db5053-fc64-4418-ddf5-676cde2f12d7"
      },
      "source": [
        "\n",
        "### CLASSIFY MNIST PICTURES\n",
        "\n",
        "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
        "data = mnist.load_data()\n",
        "\n",
        "# The datapoints are in mnistData[0][0]\n",
        "X = data[0][0][:10000].reshape([10000,28*28])\n",
        "X = X/255.0\n",
        "\n",
        "# The labels are in mnistData[0][1]\n",
        "Y = data[0][1][:10000]\n",
        "\n",
        "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size = 0.25)\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# fit the model to the training data\n",
        "model = FeedforwardNeuralNetworkSGDWithRegularization([784, 256, 128, 64, 10], 0.5, 32)\n",
        "#model = FeedforwardNeuralNetworkSGD([64, 16, 16, 10], 0.5, 32)\n",
        "loss_history, accuracy_history = model.fit(trainX, trainY, testX, testY, 1000, 100)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch = 100, loss = 3736.302477\n",
            "[INFO] epoch = 200, loss = 4659.652868\n",
            "[INFO] epoch = 300, loss = 3596.506005\n",
            "[INFO] epoch = 400, loss = 3595.196957\n",
            "[INFO] epoch = 500, loss = 3587.613891\n",
            "[INFO] epoch = 600, loss = 3483.370206\n",
            "[INFO] epoch = 700, loss = 3486.339113\n",
            "[INFO] epoch = 800, loss = 3462.045484\n",
            "[INFO] epoch = 900, loss = 3593.609058\n",
            "[INFO] epoch = 1000, loss = 3541.023578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdLNBZD1bN7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d311072-b12e-4ab3-ad0c-dbf783aa9c6a"
      },
      "source": [
        "# Plot Loss vs epoch\n",
        "plt.plot(loss_history)\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot test accuracy vs epoch\n",
        "plt.plot(accuracy_history)\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# print the classification performance\n",
        "print(\"Training set accuracy\")\n",
        "predictedY = model.predict(trainX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "trainY = trainY.argmax(axis=1)\n",
        "print(classification_report(trainY, predictedY))\n",
        "\n",
        "print(\"Test set accuracy\")\n",
        "predictedY = model.predict(testX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "testY = testY.argmax(axis=1)\n",
        "print(classification_report(testY, predictedY))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       771\n",
            "           1       0.00      0.00      0.00       808\n",
            "           2       0.00      0.00      0.00       730\n",
            "           3       0.00      0.00      0.00       777\n",
            "           4       0.00      0.00      0.00       760\n",
            "           5       0.09      1.00      0.16       658\n",
            "           6       0.00      0.00      0.00       750\n",
            "           7       0.00      0.00      0.00       793\n",
            "           8       0.00      0.00      0.00       718\n",
            "           9       0.00      0.00      0.00       735\n",
            "\n",
            "    accuracy                           0.09      7500\n",
            "   macro avg       0.01      0.10      0.02      7500\n",
            "weighted avg       0.01      0.09      0.01      7500\n",
            "\n",
            "Test set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       230\n",
            "           1       0.00      0.00      0.00       319\n",
            "           2       0.00      0.00      0.00       261\n",
            "           3       0.00      0.00      0.00       255\n",
            "           4       0.00      0.00      0.00       220\n",
            "           5       0.08      1.00      0.15       205\n",
            "           6       0.00      0.00      0.00       264\n",
            "           7       0.00      0.00      0.00       277\n",
            "           8       0.00      0.00      0.00       226\n",
            "           9       0.00      0.00      0.00       243\n",
            "\n",
            "    accuracy                           0.08      2500\n",
            "   macro avg       0.01      0.10      0.02      2500\n",
            "weighted avg       0.01      0.08      0.01      2500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT6NVUwqbU7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pt9gJ685Y89",
        "colab_type": "text"
      },
      "source": [
        "# Question 4\n",
        "`Add options to choose between several activation functions: sigmoid, ReLU, and exponential linear unit and run each setting on MNIST to see if there are differences in classification performance or computational time. Generate the same plots.`\n",
        "\n",
        "### Answer\n",
        "Since it's not specified whether I should use a different activation for the output layer, for simplicity, I'll assume the same activation function for all layers. However, I understand that for the output layer ReLU/ELU might not be the best choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccZMG2r45XFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedforwardNeuralNetworkSGDWithDiffActivations:\n",
        "    \n",
        "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
        "    def __init__(self, layers, alpha = 0.1, batchSize = 32, activation_fn_ID=1):\n",
        "        # list of weight matrices between layers\n",
        "        self.W = []\n",
        "        \n",
        "        # network architecture will be a vector of numbers of nodes for each layer\n",
        "        self.layers = layers\n",
        "        \n",
        "        # learning rate\n",
        "        self.alpha = alpha\n",
        "        \n",
        "        # batch size\n",
        "        self.batchSize = batchSize\n",
        "\n",
        "\n",
        "########################## Instantiate the Model with the desired Activation Function #############\n",
        "        # Activation functions optionality\n",
        "        if activation_fn_ID == 1:\n",
        "            print('using sigmoid')\n",
        "            self.activation_fn = self.sigmoid\n",
        "            self.activation_fn_derivative = self.sigmoidDerivative\n",
        "        elif activation_fn_ID == 2:\n",
        "            print('using relu')\n",
        "            self.activation_fn = self.ReLU\n",
        "            self.activation_fn_derivative = self.ReLUDerivative\n",
        "        elif activation_fn_ID == 3:\n",
        "            print('using elu')\n",
        "            self.activation_fn = self.ELU\n",
        "            self.activation_fn_derivative = self.ELUDerivative\n",
        "########################## Instantiate the Model with the desired Activation Function #############\n",
        "\n",
        "\n",
        "\n",
        "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
        "        \n",
        "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
        "        for i in np.arange(0, len(layers) - 2):\n",
        "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
        "            \n",
        "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
        "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
        "        \n",
        "    # define the sigmoid activation\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0 / (1 + np.exp(-x))\n",
        "    \n",
        "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
        "    def sigmoidDerivative(self, z):\n",
        "        return z * (1 - z)\n",
        "\n",
        "\n",
        "########################## Additional Activation Functions Defined ####################\n",
        "    # define the ReLu activation\n",
        "    def ReLU(self, x):\n",
        "        out = x * (x>0) # keep only elements which are greater than zero\n",
        "        return out\n",
        "\n",
        "    # define the ReLu derivative\n",
        "    def ReLUDerivative(self, x):\n",
        "        dx = 1 * (x>0) \n",
        "        return dx\n",
        "    \n",
        "    # define the Exponential linear unit activation\n",
        "    def ELU(self, x, alpha=0.1):\n",
        "        return np.where(x>0, x, alpha*np.exp(x)-1)\n",
        "        \n",
        "    # define the ELU derivative\n",
        "    def ELUDerivative(self, x, alpha=0.1):\n",
        "        return np.where(x>0, 1, alpha*np.exp(x))\n",
        "########################## Additional Activation Functions Defined ####################\n",
        "\n",
        "\n",
        "    def getNextBatch(self, X, y, batchSize):\n",
        "        for i in np.arange(0, X.shape[0], batchSize):\n",
        "            yield (X[i:i + batchSize], y[i:i + batchSize])\n",
        "    \n",
        "    # fit the model\n",
        "    def fit(self, X, y, testX, testY, epochs = 10000, update = 1000):\n",
        "        # add a column of ones to the end of X\n",
        "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
        "\n",
        "        # history keeps track of all loss/accuracy vs epoch number on Test data\n",
        "        loss_history = []\n",
        "        accuracy_history = []\n",
        "\n",
        "        for epoch in np.arange(0,epochs):\n",
        "            \n",
        "            # randomize the examples\n",
        "            p = np.arange(0,X.shape[0])\n",
        "            np.random.shuffle(p)\n",
        "            X = X[p]\n",
        "            y = y[p]\n",
        "\n",
        "            # feed forward, backprop, and weight update\n",
        "            for (x, target) in self.getNextBatch(X, y, self.batchSize):\n",
        "                # make a list of output activations from the first layer\n",
        "                # (just the original x values)\n",
        "                A = [np.atleast_2d(x)]\n",
        "                \n",
        "                # feed forward\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    \n",
        "                    # feed through one layer and apply sigmoid activation\n",
        "                    net = A[layer].dot(self.W[layer])\n",
        "                    out = self.activation_fn(net)\n",
        "                    \n",
        "                    # add our network output to the list of activations\n",
        "                    A.append(out)\n",
        "                    \n",
        "                # backpropagation (coming soon!)\n",
        "                error = A[-1] - target\n",
        "                \n",
        "                D = [error * self.activation_fn_derivative(A[-1])]\n",
        "                \n",
        "                # loop backwards over the layers to build up deltas\n",
        "                for layer in np.arange(len(A) - 2, 0, -1):\n",
        "                    delta = D[-1].dot(self.W[layer].T)\n",
        "                    delta = delta * self.activation_fn_derivative(A[layer])\n",
        "                    D.append(delta)\n",
        "                    \n",
        "                # reverse the deltas since we looped in reverse\n",
        "                D = D[::-1]\n",
        "                \n",
        "                # weight update\n",
        "                for layer in np.arange(0, len(self.W)):\n",
        "                    self.W[layer] -= self.alpha * A[layer].T.dot(D[layer])\n",
        "            \n",
        "            if (epoch + 1) % update == 0:\n",
        "                loss = self.computeLoss(X,y)\n",
        "                print(\"[INFO] epoch = {}, loss = {:.6f}\".format(epoch + 1, loss))\n",
        "\n",
        "            # print(testX.shape, testY.shape, \"<< check shapes\")\n",
        "            loss_Test = self.computeLoss(testX, testY, addOnes=True)\n",
        "            loss_history.append(loss_Test)\n",
        "\n",
        "            accuracy_testX = self.get_testing_accuracy(testX, testY, epoch)\n",
        "            accuracy_history.append(accuracy_testX)\n",
        "\n",
        "        return loss_history, accuracy_history\n",
        "\n",
        "    def get_testing_accuracy(self, testX, testY, epoch):\n",
        "        predictedY = self.predict(testX)\n",
        "        predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "        testY = testY.argmax(axis=1)\n",
        "\n",
        "        accuracy_on_testX = accuracy_score(testY, predictedY)\n",
        "        \"Uncomment to display classification Report of each epoch.\"\n",
        "        # report = classification_report(testY, predictedY)\n",
        "        # print(\"[INFO] epoch = {}, accuracy = {}, classification report :\\n {}\".format(epoch + 1, \n",
        "        #                                                             accuracy_on_testX, report))\n",
        "        return accuracy_on_testX\n",
        "\n",
        "    def predict(self, X, addOnes = True):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        p = np.atleast_2d(X)\n",
        "        \n",
        "        # add a column of 1s for bias\n",
        "        if addOnes:\n",
        "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
        "        \n",
        "        # feed forward!\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            # print('shapes, p and ws', p.shape, self.W[layer].shape)\n",
        "            p = self.activation_fn(np.dot(p, self.W[layer]))\n",
        "            \n",
        "        return p\n",
        "    \n",
        "    def computeLoss(self, X, y, addOnes=False):\n",
        "        # initialize data, be sure it's the right dimension\n",
        "        y = np.atleast_2d(y)\n",
        "        \n",
        "        # feed the datapoints through the network to get predicted outputs\n",
        "        predictions = self.predict(X, addOnes = addOnes)\n",
        "        loss = np.sum((predictions - y)**2) / 2.0\n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICtSsrUyIftS",
        "colab_type": "text"
      },
      "source": [
        "#### Activation functions \n",
        "To instantiate a model\n",
        "- with `1` as activation_fn ID, will use `sigmoid`\n",
        "- with `2` as activation_fn ID, will use `ReLU`\n",
        "- with `3` as activation_fn ID, will use `ELU`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3UkepZs_4zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ba259a6-1fc9-4c42-bb01-301e51c576d6"
      },
      "source": [
        "\"With Sigmoid Activation Function\"\n",
        "\n",
        "### CLASSIFY MNIST PICTURES\n",
        "\n",
        "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
        "data = mnist.load_data()\n",
        "\n",
        "# The datapoints are in mnistData[0][0]\n",
        "X = data[0][0][:10000].reshape([10000,28*28])\n",
        "X = X/255.0\n",
        "\n",
        "# The labels are in mnistData[0][1]\n",
        "Y = data[0][1][:10000]\n",
        "\n",
        "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size = 0.25)\n",
        "\n",
        "print(trainX.shape)\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# fit the model to the training data\n",
        "model = FeedforwardNeuralNetworkSGDWithDiffActivations([784, 256, 128, 64, 10], 0.5, 32, 1)\n",
        "#model = FeedforwardNeuralNetworkSGD([64, 16, 16, 10], 0.5, 32)\n",
        "loss_history, accuracy_history = model.fit(trainX, trainY, testX, testY, 1000, 100)\n",
        "\n",
        "# Plot Loss vs epoch\n",
        "plt.plot(loss_history)\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot test accuracy vs epoch\n",
        "plt.plot(accuracy_history)\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# print the classification performance\n",
        "print(\"Training set accuracy\")\n",
        "predictedY = model.predict(trainX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "trainY = trainY.argmax(axis=1)\n",
        "print(classification_report(trainY, predictedY))\n",
        "\n",
        "print(\"Test set accuracy\")\n",
        "predictedY = model.predict(testX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "testY = testY.argmax(axis=1)\n",
        "print(classification_report(testY, predictedY))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 784)\n",
            "using sigmoid\n",
            "[INFO] epoch = 100, loss = 3749.999504\n",
            "[INFO] epoch = 200, loss = 3749.996493\n",
            "[INFO] epoch = 300, loss = 3749.999984\n",
            "[INFO] epoch = 400, loss = 3749.999983\n",
            "[INFO] epoch = 500, loss = 3749.999983\n",
            "[INFO] epoch = 600, loss = 3749.999983\n",
            "[INFO] epoch = 700, loss = 3749.999983\n",
            "[INFO] epoch = 800, loss = 3749.999982\n",
            "[INFO] epoch = 900, loss = 3749.999982\n",
            "[INFO] epoch = 1000, loss = 3749.999982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       755\n",
            "           1       0.06      0.00      0.01       852\n",
            "           2       0.00      0.00      0.00       743\n",
            "           3       0.00      0.00      0.00       752\n",
            "           4       0.00      0.00      0.00       737\n",
            "           5       0.19      0.00      0.01       636\n",
            "           6       0.10      1.00      0.19       761\n",
            "           7       0.00      0.00      0.00       807\n",
            "           8       0.00      0.00      0.00       719\n",
            "           9       0.00      0.00      0.00       738\n",
            "\n",
            "    accuracy                           0.10      7500\n",
            "   macro avg       0.03      0.10      0.02      7500\n",
            "weighted avg       0.03      0.10      0.02      7500\n",
            "\n",
            "Test set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       246\n",
            "           1       0.00      0.00      0.00       275\n",
            "           2       0.00      0.00      0.00       248\n",
            "           3       0.00      0.00      0.00       280\n",
            "           4       0.00      0.00      0.00       243\n",
            "           5       0.00      0.00      0.00       227\n",
            "           6       0.10      1.00      0.18       253\n",
            "           7       0.00      0.00      0.00       263\n",
            "           8       0.00      0.00      0.00       225\n",
            "           9       0.00      0.00      0.00       240\n",
            "\n",
            "    accuracy                           0.10      2500\n",
            "   macro avg       0.01      0.10      0.02      2500\n",
            "weighted avg       0.01      0.10      0.02      2500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpyf-b3l_4p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtxsUZJn_4mB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d2e4562-6b1f-424c-c05f-364d4a4e98ed"
      },
      "source": [
        "\"With ReLU Activation Function\"\n",
        "\n",
        "### CLASSIFY MNIST PICTURES\n",
        "\n",
        "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
        "data = mnist.load_data()\n",
        "\n",
        "# The datapoints are in mnistData[0][0]\n",
        "X = data[0][0][:10000].reshape([10000,28*28])\n",
        "X = X/255.0\n",
        "\n",
        "# The labels are in mnistData[0][1]\n",
        "Y = data[0][1][:10000]\n",
        "\n",
        "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size = 0.25)\n",
        "\n",
        "print(trainX.shape)\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# fit the model to the training data\n",
        "model = FeedforwardNeuralNetworkSGDWithDiffActivations([784, 256, 128, 64, 10], 0.5, 32, 2)\n",
        "#model = FeedforwardNeuralNetworkSGD([64, 16, 16, 10], 0.5, 32)\n",
        "loss_history, accuracy_history = model.fit(trainX, trainY, testX, testY, 1000, 100)\n",
        "\n",
        "# Plot Loss vs epoch\n",
        "plt.plot(loss_history)\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot test accuracy vs epoch\n",
        "plt.plot(accuracy_history)\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# print the classification performance\n",
        "print(\"Training set accuracy\")\n",
        "predictedY = model.predict(trainX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "trainY = trainY.argmax(axis=1)\n",
        "print(classification_report(trainY, predictedY))\n",
        "\n",
        "print(\"Test set accuracy\")\n",
        "predictedY = model.predict(testX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "testY = testY.argmax(axis=1)\n",
        "print(classification_report(testY, predictedY))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 784)\n",
            "using relu\n",
            "[INFO] epoch = 100, loss = 3750.000000\n",
            "[INFO] epoch = 200, loss = 3750.000000\n",
            "[INFO] epoch = 300, loss = 3750.000000\n",
            "[INFO] epoch = 400, loss = 3750.000000\n",
            "[INFO] epoch = 500, loss = 3750.000000\n",
            "[INFO] epoch = 600, loss = 3750.000000\n",
            "[INFO] epoch = 700, loss = 3750.000000\n",
            "[INFO] epoch = 800, loss = 3750.000000\n",
            "[INFO] epoch = 900, loss = 3750.000000\n",
            "[INFO] epoch = 1000, loss = 3750.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      1.00      0.19       772\n",
            "           1       0.00      0.00      0.00       831\n",
            "           2       0.00      0.00      0.00       751\n",
            "           3       0.00      0.00      0.00       746\n",
            "           4       0.00      0.00      0.00       742\n",
            "           5       0.00      0.00      0.00       662\n",
            "           6       0.00      0.00      0.00       761\n",
            "           7       0.00      0.00      0.00       797\n",
            "           8       0.00      0.00      0.00       710\n",
            "           9       0.00      0.00      0.00       728\n",
            "\n",
            "    accuracy                           0.10      7500\n",
            "   macro avg       0.01      0.10      0.02      7500\n",
            "weighted avg       0.01      0.10      0.02      7500\n",
            "\n",
            "Test set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      1.00      0.17       229\n",
            "           1       0.00      0.00      0.00       296\n",
            "           2       0.00      0.00      0.00       240\n",
            "           3       0.00      0.00      0.00       286\n",
            "           4       0.00      0.00      0.00       238\n",
            "           5       0.00      0.00      0.00       201\n",
            "           6       0.00      0.00      0.00       253\n",
            "           7       0.00      0.00      0.00       273\n",
            "           8       0.00      0.00      0.00       234\n",
            "           9       0.00      0.00      0.00       250\n",
            "\n",
            "    accuracy                           0.09      2500\n",
            "   macro avg       0.01      0.10      0.02      2500\n",
            "weighted avg       0.01      0.09      0.02      2500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syN6nMS2G0R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2WbwnDGBHj",
        "colab_type": "text"
      },
      "source": [
        "`Warning`: In our case, when using ELU activation for all layers, activations get too big, and exponential overflow occurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpPQhVx-Gzpx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b67a106-c3e1-4926-c2d8-a24eda461d15"
      },
      "source": [
        "\"With ELU Activation Function\"\n",
        "\n",
        "### CLASSIFY MNIST PICTURES\n",
        "\n",
        "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
        "data = mnist.load_data()\n",
        "\n",
        "# The datapoints are in mnistData[0][0]\n",
        "X = data[0][0][:10000].reshape([10000,28*28])\n",
        "X = X/255.0\n",
        "\n",
        "# The labels are in mnistData[0][1]\n",
        "Y = data[0][1][:10000]\n",
        "\n",
        "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size = 0.25)\n",
        "\n",
        "print(trainX.shape)\n",
        "\n",
        "trainY = LabelBinarizer().fit_transform(trainY)\n",
        "testY = LabelBinarizer().fit_transform(testY)\n",
        "\n",
        "# fit the model to the training data\n",
        "model = FeedforwardNeuralNetworkSGDWithDiffActivations([784, 256, 128, 64, 10], 0.5, 32, 3)\n",
        "#model = FeedforwardNeuralNetworkSGD([64, 16, 16, 10], 0.5, 32)\n",
        "loss_history, accuracy_history = model.fit(trainX, trainY, testX, testY, 1000, 100)\n",
        "\n",
        "# Plot Loss vs epoch\n",
        "plt.plot(loss_history)\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot test accuracy vs epoch\n",
        "plt.plot(accuracy_history)\n",
        "plt.title('Accuracy vs Epoch')\n",
        "plt.show()\n",
        "\n",
        "# print the classification performance\n",
        "print(\"Training set accuracy\")\n",
        "predictedY = model.predict(trainX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "trainY = trainY.argmax(axis=1)\n",
        "print(classification_report(trainY, predictedY))\n",
        "\n",
        "print(\"Test set accuracy\")\n",
        "predictedY = model.predict(testX)\n",
        "predictedY = predictedY.argmax(axis=1)\n",
        "\n",
        "testY = testY.argmax(axis=1)\n",
        "print(classification_report(testY, predictedY))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 784)\n",
            "using elu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in greater\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in greater\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch = 100, loss = nan\n",
            "[INFO] epoch = 200, loss = nan\n",
            "[INFO] epoch = 300, loss = nan\n",
            "[INFO] epoch = 400, loss = nan\n",
            "[INFO] epoch = 500, loss = nan\n",
            "[INFO] epoch = 600, loss = nan\n",
            "[INFO] epoch = 700, loss = nan\n",
            "[INFO] epoch = 800, loss = nan\n",
            "[INFO] epoch = 900, loss = nan\n",
            "[INFO] epoch = 1000, loss = nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAShElEQVR4nO3df7Bc5X3f8ffHyJbtOAUEAgNCFjYkrUgmzswG6iZtqcEg0mBRzDSQOlYaZ/gjYZrEccdycWOMPVMgTnBcO+2odqYaMvwKbcZqnA4V2My4bYq5Im5sJVZ0LaBIgBGI0AhisMy3f+xRu2xXP+7dvXe5et6vmTP3nOf57tnvozuzn91z9kKqCklSu14z7QYkSdNlEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkI5RSX4uyX+ddh969TMItGQkeSTJRdPuYz6SXJDk5ST7h7Z3TLs3adm0G5Aa8nhVrZp2E9IwPxFoyUuyPMmnkjzebZ9KsrybOznJHyb5yyT7knwlyWu6uQ8l2ZPkr5LsSHLhiHOfn+TJJMcNjP2jJH/a7Z+XZCbJ/07y7SS/Nc813J/kXyX5aneuLyRZMTD/7iTbu3Xcn+RvDcydmeQ/Jtmb5Jkknxk69yeTPJvk4SSXzqc/HdsMAh0LrgP+NvB24EeA84CPdHO/BuwGVgKnAv8CqCQ/CFwL/FhVfT9wCfDI8Imr6gHgeeCdA8M/A9zW7f828NtV9TeAtwF3jbGO9wE/D5wGHAA+DZDkB4DbgV/p1vFHwH9K8rouoP4QeBRYA5wB3DFwzvOBHcDJwM3A55NkjB51DDIIdCz4J8ANVfVUVe0FPgb8bDf3XfovrG+pqu9W1Veq/x/Y+h6wHFib5LVV9UhVfesQ578duBogyfcDP9mNHTz/2UlOrqr9VfU/DtPn6d07+sHt+wbmb62qb1TV88C/BP5x90L/08AXq2prVX0X+CTwBuDv0A+904F/XlXPV9V3qmrwBvGjVfXvqup7wObu3+LUw/5rqjkGgY4Fp9N/R3zQo90YwG8As8B/SbIryUaAqpql/w77euCpJHckOZ3RbgOu6C43XQE8VFUHn+/9wA8A30zyYJKfOkyfj1fVCUPb8wPzjw2t4bX038m/Yn1V9XJXewZwJv0X+wOHeM4nBx73Qrf7psP0qAYZBDoWPA68ZeB4dTdGVf1VVf1aVb0VeDfwgYP3Aqrqtqr6ie6xBdw06uRV9Wf0X4gv5ZWXhaiqnVV1NXBK9/i7h97lz8WZQ2v4LvD08Pq6SztnAnvoB8LqJH7xQ/NmEGipeW2S1w9sy+hfpvlIkpVJTgZ+Hfg9gCQ/leTs7sXzOfqXhF5O8oNJ3tm9y/8O8NfAy4d53tuAXwb+HvD7BweTvDfJyu5d+l92w4c7z+G8N8naJG8EbgDu7i7p3AX8wyQXJnkt/fseLwL/Hfgq8ARwY5Lv6/5Nfnyez69GGQRaav6I/ov2we164BPADPCnwNeBh7oxgHOAe4H9wB8Dv1NVX6Z/f+BG+u+4n6T/jv7Dh3ne24G/D3ypqp4eGF8HbE+yn/6N46uq6q8PcY7TR/wdwXsG5m8F/n3Xz+uBfwZQVTuA9wL/uuv3MuCyqnqpC4rLgLOB/0X/xvhPH2Yd0v8n/o9ppOlLcj/we1X1uWn3ovb4iUCSGmcQSFLjvDQkSY3zE4EkNW5Jfvf45JNPrjVr1ky7DUlaUrZt2/Z0Va0cHl+SQbBmzRpmZmam3YYkLSlJHh017qUhSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWrcRIIgybokO5LMJtk4Yn55kju7+QeSrBmaX51kf5IPTqIfSdLRGzsIkhwHfBa4FFgLXJ1k7VDZ+4Fnq+ps4BbgpqH53wL+87i9SJLmbhKfCM4DZqtqV1W9BNwBrB+qWQ9s7vbvBi5MEoAklwMPA9sn0IskaY4mEQRnAI8NHO/uxkbWVNUB4DngpCRvAj4EfOxIT5LkmiQzSWb27t07gbYlSTD9m8XXA7dU1f4jFVbVpqrqVVVv5cqVC9+ZJDVi2QTOsQc4c+B4VTc2qmZ3kmXA8cAzwPnAlUluBk4AXk7ynar6zAT6kiQdhUkEwYPAOUnOov+CfxXwM0M1W4ANwB8DVwJfqqoC/u7BgiTXA/sNAUlaXGMHQVUdSHItcA9wHPC7VbU9yQ3ATFVtAT4P3JpkFthHPywkSa8C6b8xX1p6vV7NzMxMuw1JWlKSbKuq3vD4tG8WS5KmzCCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWrcRIIgybokO5LMJtk4Yn55kju7+QeSrOnG35VkW5Kvdz/fOYl+JElHb+wgSHIc8FngUmAtcHWStUNl7weeraqzgVuAm7rxp4HLquqHgQ3AreP2I0mam0l8IjgPmK2qXVX1EnAHsH6oZj2wudu/G7gwSarqT6rq8W58O/CGJMsn0JMk6ShNIgjOAB4bON7djY2sqaoDwHPASUM17wEeqqoXJ9CTJOkoLZt2AwBJzqV/uejiw9RcA1wDsHr16kXqTJKOfZP4RLAHOHPgeFU3NrImyTLgeOCZ7ngV8AfA+6rqW4d6kqraVFW9quqtXLlyAm1LkmAyQfAgcE6Ss5K8DrgK2DJUs4X+zWCAK4EvVVUlOQH4IrCxqv7bBHqRJM3R2EHQXfO/FrgH+HPgrqranuSGJO/uyj4PnJRkFvgAcPArptcCZwO/nuRr3XbKuD1Jko5eqmraPcxZr9ermZmZabchSUtKkm1V1Rse9y+LJalxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklq3ESCIMm6JDuSzCbZOGJ+eZI7u/kHkqwZmPtwN74jySWT6EeSdPTGDoIkxwGfBS4F1gJXJ1k7VPZ+4NmqOhu4Bbipe+xa4CrgXGAd8Dvd+SRJi2QSnwjOA2araldVvQTcAawfqlkPbO727wYuTJJu/I6qerGqHgZmu/NJkhbJJILgDOCxgePd3djImqo6ADwHnHSUjwUgyTVJZpLM7N27dwJtS5JgCd0srqpNVdWrqt7KlSun3Y4kHTMmEQR7gDMHjld1YyNrkiwDjgeeOcrHSpIW0CSC4EHgnCRnJXkd/Zu/W4ZqtgAbuv0rgS9VVXXjV3XfKjoLOAf46gR6kiQdpWXjnqCqDiS5FrgHOA743aranuQGYKaqtgCfB25NMgvsox8WdHV3AX8GHAB+qaq+N25PkqSjl/4b86Wl1+vVzMzMtNuQpCUlybaq6g2PL5mbxZKkhWEQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1bqwgSLIiydYkO7ufJx6ibkNXszPJhm7sjUm+mOSbSbYnuXGcXiRJ8zPuJ4KNwH1VdQ5wX3f8CklWAB8FzgfOAz46EBifrKq/Cfwo8ONJLh2zH0nSHI0bBOuBzd3+ZuDyETWXAFural9VPQtsBdZV1QtV9WWAqnoJeAhYNWY/kqQ5GjcITq2qJ7r9J4FTR9ScATw2cLy7G/u/kpwAXEb/U4UkaREtO1JBknuBN4+Yum7woKoqSc21gSTLgNuBT1fVrsPUXQNcA7B69eq5Po0k6RCOGARVddGh5pJ8O8lpVfVEktOAp0aU7QEuGDheBdw/cLwJ2FlVnzpCH5u6Wnq93pwDR5I02riXhrYAG7r9DcAXRtTcA1yc5MTuJvHF3RhJPgEcD/zKmH1IkuZp3CC4EXhXkp3ARd0xSXpJPgdQVfuAjwMPdtsNVbUvySr6l5fWAg8l+VqSXxizH0nSHKVq6V1l6fV6NTMzM+02JGlJSbKtqnrD4/5lsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjRsrCJKsSLI1yc7u54mHqNvQ1exMsmHE/JYk3xinF0nS/Iz7iWAjcF9VnQPc1x2/QpIVwEeB84HzgI8OBkaSK4D9Y/YhSZqncYNgPbC5298MXD6i5hJga1Xtq6pnga3AOoAkbwI+AHxizD4kSfM0bhCcWlVPdPtPAqeOqDkDeGzgeHc3BvBx4DeBF470REmuSTKTZGbv3r1jtCxJGrTsSAVJ7gXePGLqusGDqqokdbRPnOTtwNuq6leTrDlSfVVtAjYB9Hq9o34eSdLhHTEIquqiQ80l+XaS06rqiSSnAU+NKNsDXDBwvAq4H3gH0EvySNfHKUnur6oLkCQtmnEvDW0BDn4LaAPwhRE19wAXJzmxu0l8MXBPVf2bqjq9qtYAPwH8hSEgSYtv3CC4EXhXkp3ARd0xSXpJPgdQVfvo3wt4sNtu6MYkSa8CqVp6l9t7vV7NzMxMuw1JWlKSbKuq3vC4f1ksSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqXKpq2j3MWZK9wKPT7mOOTgaennYTi8w1t8E1Lx1vqaqVw4NLMgiWoiQzVdWbdh+LyTW3wTUvfV4akqTGGQSS1DiDYPFsmnYDU+Ca2+CalzjvEUhS4/xEIEmNMwgkqXEGwQQlWZFka5Kd3c8TD1G3oavZmWTDiPktSb6x8B2Pb5w1J3ljki8m+WaS7UluXNzu5ybJuiQ7kswm2ThifnmSO7v5B5KsGZj7cDe+I8kli9n3OOa75iTvSrItyde7n+9c7N7nY5zfcTe/Osn+JB9crJ4noqrcJrQBNwMbu/2NwE0jalYAu7qfJ3b7Jw7MXwHcBnxj2utZ6DUDbwT+QVfzOuArwKXTXtMh1nkc8C3grV2v/xNYO1Tzi8C/7favAu7s9td29cuBs7rzHDftNS3wmn8UOL3b/yFgz7TXs5DrHZi/G/h94IPTXs9cNj8RTNZ6YHO3vxm4fETNJcDWqtpXVc8CW4F1AEneBHwA+MQi9Dop815zVb1QVV8GqKqXgIeAVYvQ83ycB8xW1a6u1zvor33Q4L/F3cCFSdKN31FVL1bVw8Bsd75Xu3mvuar+pKoe78a3A29IsnxRup6/cX7HJLkceJj+epcUg2CyTq2qJ7r9J4FTR9ScATw2cLy7GwP4OPCbwAsL1uHkjbtmAJKcAFwG3LcQTU7AEdcwWFNVB4DngJOO8rGvRuOsedB7gIeq6sUF6nNS5r3e7k3ch4CPLUKfE7ds2g0sNUnuBd48Yuq6wYOqqiRH/d3cJG8H3lZVvzp83XHaFmrNA+dfBtwOfLqqds2vS70aJTkXuAm4eNq9LLDrgVuqan/3AWFJMQjmqKouOtRckm8nOa2qnkhyGvDUiLI9wAUDx6uA+4F3AL0kj9D/vZyS5P6quoApW8A1H7QJ2FlVn5pAuwtlD3DmwPGqbmxUze4u3I4HnjnKx74ajbNmkqwC/gB4X1V9a+HbHds46z0fuDLJzcAJwMtJvlNVn1n4tidg2jcpjqUN+A1eeeP05hE1K+hfRzyx2x4GVgzVrGHp3Cwea83074f8B+A1017LEda5jP5N7rP4fzcSzx2q+SVeeSPxrm7/XF55s3gXS+Nm8ThrPqGrv2La61iM9Q7VXM8Su1k89QaOpY3+tdH7gJ3AvQMvdj3gcwN1P0//huEs8E9HnGcpBcG810z/HVcBfw58rdt+YdprOsxafxL4C/rfLLmuG7sBeHe3/3r63xiZBb4KvHXgsdd1j9vBq/SbUZNcM/AR4PmB3+vXgFOmvZ6F/B0PnGPJBYH/iQlJapzfGpKkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXH/B4luW7Zxj6BpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      1.00      0.19       773\n",
            "           1       0.00      0.00      0.00       842\n",
            "           2       0.00      0.00      0.00       735\n",
            "           3       0.00      0.00      0.00       768\n",
            "           4       0.00      0.00      0.00       731\n",
            "           5       0.00      0.00      0.00       645\n",
            "           6       0.00      0.00      0.00       745\n",
            "           7       0.00      0.00      0.00       810\n",
            "           8       0.00      0.00      0.00       708\n",
            "           9       0.00      0.00      0.00       743\n",
            "\n",
            "    accuracy                           0.10      7500\n",
            "   macro avg       0.01      0.10      0.02      7500\n",
            "weighted avg       0.01      0.10      0.02      7500\n",
            "\n",
            "Test set accuracy\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      1.00      0.17       228\n",
            "           1       0.00      0.00      0.00       285\n",
            "           2       0.00      0.00      0.00       256\n",
            "           3       0.00      0.00      0.00       264\n",
            "           4       0.00      0.00      0.00       249\n",
            "           5       0.00      0.00      0.00       218\n",
            "           6       0.00      0.00      0.00       269\n",
            "           7       0.00      0.00      0.00       260\n",
            "           8       0.00      0.00      0.00       236\n",
            "           9       0.00      0.00      0.00       235\n",
            "\n",
            "    accuracy                           0.09      2500\n",
            "   macro avg       0.01      0.10      0.02      2500\n",
            "weighted avg       0.01      0.09      0.02      2500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyEeEXhwIULX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}